import re
"""
主要解决对于连续的英文或数字，若使用单个字符造成文本过长且边界出现问题。
并且将识别为UNK的用自己标记ENG替换。需要将vocab.txt里面的[unused1]修改为[ENG]。
"""

text = "2020年5月17日10时27分许，事主王大锤（联系电话：15111111111）到我所报案称：当日9时许，其从宝安区航城街道甲田岗工业区3栋419宿舍醒来时，发现放在枕头旁边两部手机（一部蓝色机身华为手机，型号：nova5i,移动版，现价值：1100元人民币，一部银色VIVO手机，型号是p1us6,移动版，现价值：1200元人民币）被盗。网址：www.baidu.com。联系我。"
entities = [('2020年5月17日10时27分', 0, 16), ('事主王大锤', 20, 23), ('15111111111', 29, 40), ('当日9时', 48, 52), ('宝安区航城街道甲田岗工业区3栋419宿舍', 56, 76), ('手机', 90, 92), ('手机', 101, 103), ('1100元', 122, 127), ('手机', 139, 141), ('1200元', 159, 164), ('www.baidu.com', 174, 187)]

def judge(s):
    s = s.lower()
    if re.search('[0-9a-z]', s):
        return True
    return False


def split_text(text):
    res = []
    tmp = []
    for i in text:
        if judge(i):
            tmp.append(i)
        else:
            if tmp:
                res.append("".join(tmp))
                tmp = []
            res.append(i)
    if tmp:
        res.append("".join(tmp))
    return res

res_text = []
res_entities = []
l = 0
tmp_start = 0
tmp_end = 0
for i,ent in enumerate(entities):
    start = ent[1]
    end = ent[2]
    span = ent[0]
    left = text[tmp_start:start]
    right = text[end:]
    span_split = split_text(span)
    left_split = split_text(left)
    res_text.extend(left_split)
    l = len(res_text)
    res_text.extend(span_split)
    if len(span_split) == 1:
        res_entities.append((res_text[l:l+1], l, l))
    else:
        res_entities.append((res_text[l:l + len(span_split)], l, l + len(span_split)-1))
    tmp_start = len("".join(res_text))
    if i == len(entities) - 1 and right:
        res_text.extend(split_text(right))

# for ent in res_entities:
#     print(ent[0], res_text[ent[1]:ent[2]+1])

print(res_text)
print(res_entities)

from transformers import BertTokenizer
tokenizer = BertTokenizer.from_pretrained('../model_hub/chinese-bert-wwm-ext/')
# print(tokenizer.vocab)
token_ids = tokenizer.convert_tokens_to_ids(res_text)
tokens = tokenizer.convert_ids_to_tokens(token_ids)
print(tokens)

token_text = []
for t in res_text:
    if tokenizer.convert_ids_to_tokens(tokenizer.convert_tokens_to_ids(([t]))) == ['[UNK]']:
        token_text.append('[ENG]')
    else:
        token_text.append(t)
print(token_text)
token_ids = tokenizer.convert_tokens_to_ids(token_text)
tokens = tokenizer.convert_ids_to_tokens(token_ids)
print(tokens)

"""
['2020', '年', '5', '月', '17', '日', '10', '时', '27', '分', '许', '，', '事', '主', '事', '主', '王', '大', '锤', '系', '电', '话', '：', '15111111111', '）', '到', '我', '所', '报', '案', '称', '：', '当', '日', '9', '时', '许', '，', '其', '从', '宝', '安', '区', '航', '城', '街', '道', '甲', '田', '岗', '工', '业', '区', '3', '栋', '419', '宿', '舍', '醒', '来', '时', '，', '发', '现', '放', '在', '枕', '头', '旁', '边', '两', '部', '手', '机', '（', '一', '部', '蓝', '色', '机', '身', '华', '为', '手', '机', '，', '型', '号', '：', 'nova5i', ',', '移', '动', '版', '，', '现', '价', '值', '：', '1100', '元', '人', '民', '币', '，', '一', '部', '银', '色', 'VIVO', '手', '机', '，', '型', '号', '是', 'p1us6', ',', '移', '动', '版', '，', '现', '价', '值', '：', '1200', '元', '人', '民', '币', '）', '被', '盗', '。', '网', '址', '：', 'www', '.', 'baidu', '.', 'com', '。', '联', '系', '我', '。']
[(['2020', '年', '5', '月', '17', '日', '10', '时', '27', '分'], 0, 9), (['事', '主', '王', '大', '锤'], 14, 18), (['15111111111'], 23, 23), (['当', '日', '9', '时'], 32, 35), (['宝', '安', '区', '航', '城', '街', '道', '甲', '田', '岗', '工', '业', '区', '3', '栋', '419', '宿', '舍'], 40, 57), (['手', '机'], 72, 73), (['手', '机'], 83, 84), (['1100', '元'], 99, 100), (['手', '机'], 110, 111), (['1200', '元'], 126, 127), (['www', '.', 'baidu', '.', 'com'], 138, 142)]
['2020', '年', '5', '月', '17', '日', '10', '时', '27', '分', '许', '，', '事', '主', '事', '主', '王', '大', '锤', '系', '电', '话', '：', '[UNK]', '）', '到', '我', '所', '报', '案', '称', '：', '当', '日', '9', '时', '许', '，', '其', '从', '宝', '安', '区', '航', '城', '街', '道', '甲', '田', '岗', '工', '业', '区', '3', '栋', '419', '宿', '舍', '醒', '来', '时', '，', '发', '现', '放', '在', '枕', '头', '旁', '边', '两', '部', '手', '机', '（', '一', '部', '蓝', '色', '机', '身', '华', '为', '手', '机', '，', '型', '号', '：', '[UNK]', ',', '移', '动', '版', '，', '现', '价', '值', '：', '1100', '元', '人', '民', '币', '，', '一', '部', '银', '色', '[UNK]', '手', '机', '，', '型', '号', '是', '[UNK]', ',', '移', '动', '版', '，', '现', '价', '值', '：', '1200', '元', '人', '民', '币', '）', '被', '盗', '。', '网', '址', '：', 'www', '.', 'baidu', '.', 'com', '。', '联', '系', '我', '。']
['2020', '年', '5', '月', '17', '日', '10', '时', '27', '分', '许', '，', '事', '主', '事', '主', '王', '大', '锤', '系', '电', '话', '：', '[ENG]', '）', '到', '我', '所', '报', '案', '称', '：', '当', '日', '9', '时', '许', '，', '其', '从', '宝', '安', '区', '航', '城', '街', '道', '甲', '田', '岗', '工', '业', '区', '3', '栋', '419', '宿', '舍', '醒', '来', '时', '，', '发', '现', '放', '在', '枕', '头', '旁', '边', '两', '部', '手', '机', '（', '一', '部', '蓝', '色', '机', '身', '华', '为', '手', '机', '，', '型', '号', '：', '[ENG]', ',', '移', '动', '版', '，', '现', '价', '值', '：', '1100', '元', '人', '民', '币', '，', '一', '部', '银', '色', '[ENG]', '手', '机', '，', '型', '号', '是', '[ENG]', ',', '移', '动', '版', '，', '现', '价', '值', '：', '1200', '元', '人', '民', '币', '）', '被', '盗', '。', '网', '址', '：', 'www', '.', 'baidu', '.', 'com', '。', '联', '系', '我', '。']
['2020', '年', '5', '月', '17', '日', '10', '时', '27', '分', '许', '，', '事', '主', '事', '主', '王', '大', '锤', '系', '电', '话', '：', '[ENG]', '）', '到', '我', '所', '报', '案', '称', '：', '当', '日', '9', '时', '许', '，', '其', '从', '宝', '安', '区', '航', '城', '街', '道', '甲', '田', '岗', '工', '业', '区', '3', '栋', '419', '宿', '舍', '醒', '来', '时', '，', '发', '现', '放', '在', '枕', '头', '旁', '边', '两', '部', '手', '机', '（', '一', '部', '蓝', '色', '机', '身', '华', '为', '手', '机', '，', '型', '号', '：', '[ENG]', ',', '移', '动', '版', '，', '现', '价', '值', '：', '1100', '元', '人', '民', '币', '，', '一', '部', '银', '色', '[ENG]', '手', '机', '，', '型', '号', '是', '[ENG]', ',', '移', '动', '版', '，', '现', '价', '值', '：', '1200', '元', '人', '民', '币', '）', '被', '盗', '。', '网', '址', '：', 'www', '.', 'baidu', '.', 'com', '。', '联', '系', '我', '。']
"""
