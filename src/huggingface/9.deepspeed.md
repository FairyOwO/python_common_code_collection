**Deep中文文档**

# 训练设置

## 参数解析

一个例子简单明了：

```python
parser = argparse.ArgumentParser(description='My training script.')
parser.add_argument('--local_rank', type=int, default=-1,
                    help='local rank passed from distributed launcher')
# Include DeepSpeed configuration arguments
parser = deepspeed.add_config_arguments(parser)
cmd_args = parser.parse_args()
```

## 训练初始化

还是一个例子：

```python
model_engine, optimizer, _, _ = deepspeed.initialize(args=cmd_args,
                                                     model=net,
                                                     model_parameters=net.parameters())
```

看一下里面的参数：

![image-20230419091554809](9.deepspeed.assets\image-20230419091554809.png)

返回值：

![image-20230419091718073](9.deepspeed.assets\image-20230419091718073.png)

## 分布式初始化

可选的分布式后端初始化与deepspeed.initialize()分开。在用户希望在调用deepspeed.initialize()之前使用torch分布式调用的情况下非常有用，例如在使用模型并行、管道并行或某些数据加载器的情况。

![image-20230419091858240](9.deepspeed.assets\image-20230419091858240.png)

# 推理设置

例子：

```python
engine = deepspeed.init_inference(model=net, config=config)
```

# 训练API

```python
for step, batch in enumerate(data_loader):
    #forward() method
    loss = model_engine(batch)

    #runs backpropagation
    model_engine.backward(loss)

    #weight update
    model_engine.step()
```

# 推理API

```python
for step, batch in enumerate(data_loader):
    #forward() method
    loss = engine(batch)
```

# 模型检查点

DeepSpeed中的激活检查点API可以用来实现一系列与激活检查点有关的内存优化。这些包括在使用模型并行时跨GPU的激活分区、CPU检查点、连续的内存优化等。

# ZeRO

ZeRO利用数据并行的聚合计算和内存资源来减少用于模型训练的每个设备（GPU）的内存和计算要求。ZeRO通过将各种模型训练状态（权重、梯度和优化器状态）在分布式训练硬件中的可用设备（GPU和CPU）上进行划分，减少每个GPU的内存消耗。具体来说，ZeRO是作为优化的增量阶段来实现的，早期阶段的优化可以在后期阶段使用。要深入了解ZeRO，请看我们的论文。

- **Stage 1**: The optimizer states (e.g., for [Adam optimizer](https://arxiv.org/abs/1412.6980), 32-bit weights, and the first, and second moment estimates) are partitioned across the processes, so that each process updates only its partition.
- **Stage 2**: The reduced 32-bit gradients for updating the model weights are also partitioned such that each process retains only the gradients corresponding to its portion of the optimizer states.
- **Stage 3**: The 16-bit model parameters are partitioned across the processes. ZeRO-3 will automatically collect and partition them during the forward and backward passes.

In addition, ZeRO-3 includes the infinity offload engine to form ZeRO-Infinity (paper), which can offload to both CPU and NVMe memory for huge memory savings.

要为DeepSpeed模型启用ZeRO优化，我们只需将zero_optimization键添加到DeepSpeed JSON配置中。关于zero_optimization键的配置旋钮的完整描述可以在这里找到。

## 阶段1：

```python
{
    "zero_optimization": {
        "stage": 1,
        "reduce_bucket_size": 5e8
    }
}
```

如上所示，我们在zero_optimization键中设置了两个字段。具体来说，我们将阶段字段设置为1，并将梯度缩减的可选reduce_bucket_size设置为500M。启用ZeRO stage 1后，模型现在可以在8个GPU上顺利训练而不会出现内存不足的情况。下面我们提供一些模型训练的屏幕截图：

在上面的nvidia-smi截图中，我们可以看到只有GPU 6-7被用于训练模型。通过ZeRO阶段1，我们可以通过提高数据并行度来进一步减少每个设备的内存消耗。这些节省的内存可以被用来增加模型大小和/或批量大小。相比之下，仅靠数据并行是不可能有这样的好处的。

## 阶段2：

```python
{
    "zero_optimization": {
        "stage": 2,
        "contiguous_gradients": true,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 5e8,
        "allgather_bucket_size": 5e8
    }
}
```

在上述修改中，我们将阶段字段设置为2，并配置了ZeRO阶段2中可用的其他优化旋钮。例如，我们启用了contiguous_gradients来减少后向传递时的内存碎片。关于这些优化旋钮的完整描述可以在这里找到。有了这些变化，我们现在可以启动训练运行了。 [here](https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training).

## 阶段3：

ZeRO-3是ZeRO的第三阶段，它对整个模型状态（即权重、梯度和优化器状态）进行分区，使内存的节省与数据的并行程度成线性关系。ZeRO-3可以在JSON配置中启用。关于这些配置的完整描述可在这里找到。[here](https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training).

ZeRO-Infinity使用DeepSpeed的infinity卸载引擎，将完整的模型状态卸载到CPU或NVMe内存，允许更大的模型尺寸。卸载可以在DeepSpeed配置内启用：

```python
{
    "zero_optimization": {
        "stage": 3,
        "contiguous_gradients": true,
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_prefetch_bucket_size": 1e7,
        "stage3_param_persistence_threshold": 1e5,
        "reduce_bucket_size": 1e7,
        "sub_group_size": 1e9,
        "offload_optimizer": {
            "device": "cpu"
         },
        "offload_param": {
            "device": "cpu"
       }
   }
}
```

ZeRO-Infinity与ZeRO-Offload： DeepSpeed首次将ZeRO-Offload的卸载功能纳入其中，这是一个将优化器和梯度状态卸载到ZeRO-2的CPU内存的系统。ZeRO-Infinity是ZeRO-3的下一代卸载功能。ZeRO-Infinity能够比ZeRO-Offload卸载更多的数据，并有更有效的带宽利用和计算与通信的重叠。
