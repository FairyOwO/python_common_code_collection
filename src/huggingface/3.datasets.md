直接看代码：

```python
from datasets import load_dataset
from datasets import list_datasets
from pprint import pprint

# 用于展示可用的数据集
pprint(list_datasets())

# 加载数据集
datasets = load_dataset("madao33/new-title-chinese")

# 指定数据
datasets = load_dataset("madao33/new-title-chinese", split="train")
print(datasets)

# 展示数据
datasets = load_dataset("madao33/new-title-chinese")
# 以字典的形式返回数据，键为类型，值为列表
print(datasets["train"][:2])

# 自己划分训练测试数据
datasets = load_dataset("madao33/new-title-chinese")
datasets = datasets["train"]
datasets = datasets.train_test_split(test_size=0.1)
print(datasets)

# 数据的选择和过滤
datasets = load_dataset("madao33/new-title-chinese")
# 通过select根据索引选择
select_datasets = datasets["train"].select([0, 2])
for example in select_datasets:
    # 每一条以字典的形式返回
    print(example)
# 通过filter进行过滤选择
filter_datasets = datasets["train"].filter(lambda example: "中国" in example["title"])
for example in filter_datasets:
    print(example)
    break
    
通过map对每一条数据进行处理
from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained(r"C:\Users\Administrator\Desktop\src\ner\model_hub\ner")


def process(example):
    inputs = tokenizer(example["title"],
                       max_length=64,
                       truncation=True,
                       padding="max_length")
    return inputs


processed_datasets = datasets.map(process, batched=True)
print(processed_datasets)
print(processed_datasets["train"][0])

# 保存和加载数据
from datasets import load_from_disk

processed_datasets.save_to_disk("./news_data")
datasets = load_from_disk("./news_data")
print(datasets)
```

加载自定义的数据，可以加载json、csv等格式的数据，也可以zidingpy文件来加载数据，一般情况下，使用json或者csv格式的数据较为简单方便。

json数据的格式：

```json
{
  "version": "v1.0",
  "data": [
    {
      "title": "望海楼美国打“台湾牌”是危险的赌",
      "content": "近期，美国国会众院通过法案，重申美国对台湾的承诺。"
    },
    {
      "title": "望海楼美国打“台湾牌”是危险的赌",
      "content": "近期，美国国会众院通过法案，重申美国对台湾的承诺。"
    }
  ]
}

```

加载数据代码：

```python
# 格式化加载数据
datasets = load_dataset("json", data_files=["data.json"], field="data")
print(datasets)
print(datasets["train"][:2])
```

```
DatasetDict({
    train: Dataset({
        features: ['title', 'content'],
        num_rows: 2
    })
})
{'title': ['望海楼美国打“台湾牌”是危险的赌', '望海楼美国打“台湾牌”是危险的赌'], 'content': ['近期，美国国会众院通过法案，重申美国对台湾的承诺。', '近期，美国国会众院通过法案，重申美国对台湾的承诺。']}
```

查看字段信息：

```python
datasets["train"].features
```



